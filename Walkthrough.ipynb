{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must import some necessary packages. If you do not have them you will need to do pip install (name of the package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob as tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the file. Change the path to whatever you saved the csv to when you first got the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/PycharmProjects/untitled3/giants4.csv', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will look at the what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             TimeStamp                                              Tweet  \\\n",
      "0  2017-11-16 23:57:49  b'RT @BackAftaThis: Mike Francesa goes bonkers...   \n",
      "1  2017-11-16 23:56:16  b'Fluker should be part of this O-Line next se...   \n",
      "2  2017-11-16 23:55:56  b'Are the #Giants worth a look against the #Ch...   \n",
      "3  2017-11-16 23:54:56  b'RT @TikiBarber: Talking shop with the NFL\\xe...   \n",
      "4  2017-11-16 23:54:11  b'RT @JordanRaanan: 1. Sterling Shepard, Evan ...   \n",
      "\n",
      "                   Location  \n",
      "0                    towson  \n",
      "1  07444üíôüèà‚û°Ô∏è13210üçäüéì‚û°Ô∏è90254üå¥  \n",
      "2           Fort Lauderdale  \n",
      "3                      NYC   \n",
      "4  07444üíôüèà‚û°Ô∏è13210üçäüéì‚û°Ô∏è90254üå¥  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few things just set up to remove emojis, and get the words tokenized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    "\n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "\n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    "\n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to get the sentiment scores for all of the tweets and put them into a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "sentiment_scores = []\n",
    "\n",
    "\n",
    "\n",
    "for index, entry in df.iterrows():\n",
    "    tweet = tb(entry['Tweet'])\n",
    "    sentiment_scores.append(tweet.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should add the sentiment scores to our dataframe. I decided to remove tweets with 0 sentiment to try to get a better sense of the feeling about a team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = sentiment_scores\n",
    "df = df[df.sentiment != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to do some investigation. There are all kinds of questions we can ask. One easy one is to get the average sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0657596699182\n"
     ]
    }
   ],
   "source": [
    "print (sum(df.sentiment)/len(df.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do some more subsetting using the location. First, I get rid of all empty locations, and then I find locations that contain the string 'NY' for New York "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00562560211736\n"
     ]
    }
   ],
   "source": [
    "dfNYC = df.dropna()\n",
    "\n",
    "dfNYC = dfNYC[dfNYC.Location.str.contains('NY')]\n",
    "\n",
    "print(sum(dfNYC.sentiment)/len(dfNYC.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see New York fans tweet more negatively about the Giants than the general population. This is just one example of something you can look at. Try to find something interesting about your data or your query. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
